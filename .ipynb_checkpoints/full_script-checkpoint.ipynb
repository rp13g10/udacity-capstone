{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Capstone - Sparkify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import pyspark.ml as sm\n",
    "import pyspark.ml.classification as smc\n",
    "import pyspark.ml.evaluation as sme\n",
    "import pyspark.ml.feature as smf\n",
    "import pyspark.ml.tuning as smt\n",
    "import pyspark.sql.functions as ssf\n",
    "import pyspark.sql.types as sst\n",
    "import pyspark.sql.window as ssw\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input\n",
    "Running this script on the full dataset takes ~3 hours on my own local spark instance, suggest using the mini dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple toggle, use full/mini dataset\n",
    "use_full_dataset = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(use_full_dataset, bool), 'Invalid input for use_full_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a spark session\n",
    "spark = SparkSession.builder.appName(\n",
    "    'Sparkify'\n",
    ").config(\n",
    "    # Use all cores, max 4 retries per task\n",
    "    'spark.master', 'local[*,4]'\n",
    ").config(\n",
    "    # Max 4 retries per task\n",
    "    'spark.task.maxFailures', '4'\n",
    ").config(\n",
    "    # Required to prevent out-of-memory issues\n",
    "    'spark.driver.memory', '24g'\n",
    ").config(\n",
    "    # Required to prevent out-of-memory issues\n",
    "    'spark.executor.memory', '24g'\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick script to fetch sample data from s3. While this script has been tested on AWS, it was ultimately executed on a Local spark deployment.\n",
    "<br>Only run this section once, the download takes a while to complete."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Credentials need to be set via environment variables\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Mini dataset to work with\n",
    "with open('data/mini_sparkify_event_data.json', 'wb') as target:\n",
    "    s3.download_fileobj(\n",
    "        'udacity-dsnd',\n",
    "        'sparkify/mini_sparkify_event_data.json',\n",
    "        target)\n",
    "\n",
    "# Just for a laugh, load the full dataset too...\n",
    "with open('data/sparkify_event_data.json', 'wb') as target:\n",
    "    s3.download_fileobj(\n",
    "        'udacity-dsnd',\n",
    "        'sparkify/sparkify_event_data.json',\n",
    "        target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target file to laod\n",
    "data_dir = 'data'\n",
    "data_file = 'sparkify_event_data.json' if use_full_dataset else 'mini_sparkify_event_data.json'\n",
    "data_path = f\"{data_dir}/{data_file}\"\n",
    "\n",
    "# Load to spark dataframe, partition by userId\n",
    "data_raw = spark.read.json(data_path)\n",
    "data_raw = data_raw.repartition(60, 'userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check available fields\n",
    "data_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paramore</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Logan</td>\n",
       "      <td>M</td>\n",
       "      <td>161</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>218.09587</td>\n",
       "      <td>paid</td>\n",
       "      <td>Marshall, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1537448916000</td>\n",
       "      <td>19480</td>\n",
       "      <td>Ignorance (Album Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352015000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>1390009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joyce Cooling</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Keyla</td>\n",
       "      <td>F</td>\n",
       "      <td>124</td>\n",
       "      <td>Mcgee</td>\n",
       "      <td>248.11057</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1536047986000</td>\n",
       "      <td>21942</td>\n",
       "      <td>It's Time I Go (Jazz)</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352088000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>\n",
       "      <td>1919555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercury Rev</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Logan</td>\n",
       "      <td>M</td>\n",
       "      <td>162</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>151.92771</td>\n",
       "      <td>paid</td>\n",
       "      <td>Marshall, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1537448916000</td>\n",
       "      <td>19480</td>\n",
       "      <td>You're My Queen</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352233000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>1390009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-Roy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Keyla</td>\n",
       "      <td>F</td>\n",
       "      <td>125</td>\n",
       "      <td>Mcgee</td>\n",
       "      <td>146.88608</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1536047986000</td>\n",
       "      <td>21942</td>\n",
       "      <td>Black Is My Color</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352336000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>\n",
       "      <td>1919555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Ergs!</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Logan</td>\n",
       "      <td>M</td>\n",
       "      <td>163</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>8.93342</td>\n",
       "      <td>paid</td>\n",
       "      <td>Marshall, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1537448916000</td>\n",
       "      <td>19480</td>\n",
       "      <td>Sneak Attack</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352384000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>1390009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "0       Paramore  Logged In     Logan      M            161  Gregory   \n",
       "1  Joyce Cooling  Logged In     Keyla      F            124    Mcgee   \n",
       "2    Mercury Rev  Logged In     Logan      M            162  Gregory   \n",
       "3          I-Roy  Logged In     Keyla      F            125    Mcgee   \n",
       "4      The Ergs!  Logged In     Logan      M            163  Gregory   \n",
       "\n",
       "      length level                           location method      page  \\\n",
       "0  218.09587  paid                       Marshall, TX    PUT  NextSong   \n",
       "1  248.11057  paid  Atlanta-Sandy Springs-Roswell, GA    PUT  NextSong   \n",
       "2  151.92771  paid                       Marshall, TX    PUT  NextSong   \n",
       "3  146.88608  paid  Atlanta-Sandy Springs-Roswell, GA    PUT  NextSong   \n",
       "4    8.93342  paid                       Marshall, TX    PUT  NextSong   \n",
       "\n",
       "    registration  sessionId                       song  status             ts  \\\n",
       "0  1537448916000      19480  Ignorance (Album Version)     200  1538352015000   \n",
       "1  1536047986000      21942      It's Time I Go (Jazz)     200  1538352088000   \n",
       "2  1537448916000      19480            You're My Queen     200  1538352233000   \n",
       "3  1536047986000      21942          Black Is My Color     200  1538352336000   \n",
       "4  1537448916000      19480               Sneak Attack     200  1538352384000   \n",
       "\n",
       "                                           userAgent   userId  \n",
       "0  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  1390009  \n",
       "1  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...  1919555  \n",
       "2  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  1390009  \n",
       "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...  1919555  \n",
       "4  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  1390009  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "data_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = data_raw.count()\n",
    "summaries = []\n",
    "null_counts = []\n",
    "for col in data_raw.columns:\n",
    "\n",
    "    # Get no. of values\n",
    "    value_counts = data_raw.groupby(col).count()\n",
    "    value_counts = value_counts.orderBy('count', ascending=False)\n",
    "\n",
    "    # Make sure null count always comes through\n",
    "    null_count = value_counts.where(value_counts[col].isNull())\n",
    "    value_counts = value_counts.where(value_counts[col].isNotNull())\n",
    "\n",
    "    # Convert output to Pandas df, row limit to prevent any memory issues\n",
    "    value_counts = value_counts.limit(25).toPandas()\n",
    "    null_count = null_count.toPandas()\n",
    "\n",
    "    # Create summary dataframes for selected column\n",
    "    summary = pd.concat([value_counts, null_count], axis=0, ignore_index=True)\n",
    "    summary.columns = ['value', 'count']\n",
    "    summary.loc[:, 'field'] = col\n",
    "    summary = summary.sort_values(by='count', ascending=False)\n",
    "\n",
    "    if null_count.empty:\n",
    "        null_count = pd.DataFrame({\n",
    "            'value': [None],\n",
    "            'count': [0],\n",
    "            'field': [col]\n",
    "        })\n",
    "    else:\n",
    "        null_count.loc[:, 'field'] = col\n",
    "\n",
    "    # Save output to memory\n",
    "    summaries.append(summary)\n",
    "    null_counts.append(null_count)\n",
    "\n",
    "# Combine summary dataframes for each column\n",
    "value_summary = pd.concat(summaries, axis=0, ignore_index=True)\n",
    "null_summary = pd.concat(null_counts, axis=0, ignore_index=True)\n",
    "\n",
    "# Calculate counts as percentages\n",
    "value_summary.loc[:, 'percentage'] = value_summary['count']/total_rows\n",
    "null_summary.loc[:, 'percentage'] = null_summary['count']/total_rows\n",
    "\n",
    "# Standardize column order\n",
    "value_summary = value_summary[['field', 'value', 'count', 'percentage']]\n",
    "null_summary = null_summary[['field', 'value', 'count', 'percentage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk\n",
    "value_summary.to_excel('summaries/value_summary.xlsx', index=False)\n",
    "null_summary.to_excel('summaries/null_summary.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes (from running on mini dataset):\n",
    "* Records with null userId might be useful, need to look at them in more detail\n",
    "* Some encoding errors, but that shouldn't impact the model\n",
    "* itemInSession looks useful for feature engineering\n",
    "* names will need removing\n",
    "* paid/free info from level will be useful\n",
    "* what is registration? looks like it might be a timestamp\n",
    "* http response codes in response could be useful\n",
    "    * 307 is just a redirect, but 404 would be user-impacting\n",
    "* user agent could be used to get platform info\n",
    "* slightly more cancellations submitted than confirmed\n",
    "* significantly more downgrades started than confirmed\n",
    "\n",
    "Notes from full dataset\n",
    "* It looks like all null values have userId = 1261737 in this dataset?\n",
    "* No truly null values in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Records with null user IDs\n",
    "data_null = data_raw.where(data_raw['userId'].isNull())\n",
    "null_sample = data_null.limit(5).toPandas()\n",
    "null_sample\n",
    "# No results? Interesting...\n",
    "# Some userIds are populated with an empty string, not technically Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>87</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8615</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352008000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Login</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7433</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538352041000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25003</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352182000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9930</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538352254000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Login</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9930</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538352255000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist        auth firstName gender  itemInSession lastName  length level  \\\n",
       "0   None  Logged Out      None   None             87     None     NaN  paid   \n",
       "1   None  Logged Out      None   None              0     None     NaN  free   \n",
       "2   None  Logged Out      None   None              4     None     NaN  free   \n",
       "3   None  Logged Out      None   None              2     None     NaN  free   \n",
       "4   None  Logged Out      None   None              3     None     NaN  free   \n",
       "\n",
       "  location method   page  registration  sessionId  song  status  \\\n",
       "0     None    GET   Home           NaN       8615  None     200   \n",
       "1     None    PUT  Login           NaN       7433  None     307   \n",
       "2     None    GET   Home           NaN      25003  None     200   \n",
       "3     None    GET   Home           NaN       9930  None     200   \n",
       "4     None    PUT  Login           NaN       9930  None     307   \n",
       "\n",
       "              ts userAgent   userId  \n",
       "0  1538352008000      None  1261737  \n",
       "1  1538352041000      None  1261737  \n",
       "2  1538352182000      None  1261737  \n",
       "3  1538352254000      None  1261737  \n",
       "4  1538352255000      None  1261737  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Records with empty userIds\n",
    "if use_full_dataset:\n",
    "    # As noted above, this userId has ~778k records in the full\n",
    "    # dataset and is obviously anomalous\n",
    "    data_empty = data_raw.where(data_raw['userId'] == 1261737)\n",
    "else:\n",
    "    # Just search for empty strings in the mini dataset\n",
    "    data_empty = data_raw.where(data_raw['userId'] == '')\n",
    "empty_sample = data_empty.limit(5).toPandas()\n",
    "empty_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>auth</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Submit Registration</td>\n",
       "      <td>Guest</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Error</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Login</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>296350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>25023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Error</td>\n",
       "      <td>Guest</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home</td>\n",
       "      <td>Guest</td>\n",
       "      <td>1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Help</td>\n",
       "      <td>Guest</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>408325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>About</td>\n",
       "      <td>Logged Out</td>\n",
       "      <td>43747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Register</td>\n",
       "      <td>Guest</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>About</td>\n",
       "      <td>Guest</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   page        auth   count\n",
       "0   Submit Registration       Guest     401\n",
       "1                 Error  Logged Out     840\n",
       "2                 Login  Logged Out  296350\n",
       "3                  Help  Logged Out   25023\n",
       "4                 Error       Guest      74\n",
       "5                  Home       Guest    1653\n",
       "6                  Help       Guest     629\n",
       "7                  Home  Logged Out  408325\n",
       "8                 About  Logged Out   43747\n",
       "9              Register       Guest     802\n",
       "10                About       Guest     635"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which pages these records correspond do\n",
    "data_empty.groupby(['page', 'auth']).count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> It looks like these are valid records, but without a userId they can't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Logan</td>\n",
       "      <td>M</td>\n",
       "      <td>164</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "      <td>Marshall, TX</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Thumbs Up</td>\n",
       "      <td>1537448916000</td>\n",
       "      <td>19480</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538352385000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>1390009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Mikiyah</td>\n",
       "      <td>F</td>\n",
       "      <td>166</td>\n",
       "      <td>Williams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1535529597000</td>\n",
       "      <td>11733</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538354059000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1178731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Johns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Sacramento--Roseville--Arden-Arcade, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1537057337000</td>\n",
       "      <td>13907</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538354097000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>1809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Thumbs Down</td>\n",
       "      <td>1526345905000</td>\n",
       "      <td>14956</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538354433000</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebK...</td>\n",
       "      <td>1855442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Keyla</td>\n",
       "      <td>F</td>\n",
       "      <td>137</td>\n",
       "      <td>Mcgee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Downgrade</td>\n",
       "      <td>1536047986000</td>\n",
       "      <td>21942</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538354676000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>\n",
       "      <td>1919555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist       auth firstName gender  itemInSession  lastName  length level  \\\n",
       "0   None  Logged In     Logan      M            164   Gregory     NaN  paid   \n",
       "1   None  Logged In   Mikiyah      F            166  Williams     NaN  paid   \n",
       "2   None  Logged In      Kyle      M              0     Johns     NaN  free   \n",
       "3   None  Logged In      John      M              2  Anderson     NaN  paid   \n",
       "4   None  Logged In     Keyla      F            137     Mcgee     NaN  paid   \n",
       "\n",
       "                                  location method         page   registration  \\\n",
       "0                             Marshall, TX    PUT    Thumbs Up  1537448916000   \n",
       "1    New York-Newark-Jersey City, NY-NJ-PA    GET         Home  1535529597000   \n",
       "2  Sacramento--Roseville--Arden-Arcade, CA    GET         Home  1537057337000   \n",
       "3    New York-Newark-Jersey City, NY-NJ-PA    PUT  Thumbs Down  1526345905000   \n",
       "4        Atlanta-Sandy Springs-Roswell, GA    GET    Downgrade  1536047986000   \n",
       "\n",
       "   sessionId  song  status             ts  \\\n",
       "0      19480  None     307  1538352385000   \n",
       "1      11733  None     200  1538354059000   \n",
       "2      13907  None     200  1538354097000   \n",
       "3      14956  None     307  1538354433000   \n",
       "4      21942  None     200  1538354676000   \n",
       "\n",
       "                                           userAgent   userId  \n",
       "0  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  1390009  \n",
       "1  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1178731  \n",
       "2  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  1809452  \n",
       "3  \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebK...  1855442  \n",
       "4  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...  1919555  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Records with missing song info\n",
    "# Probably a valid reason for this, but worth checking just in case\n",
    "data_null = data_raw.where(\n",
    "    data_raw['userId'].isNotNull() & data_raw['song'].isNull())\n",
    "null_sample = data_null.limit(5).toPandas()\n",
    "null_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> These are still useful records, they contain all data where the page isn't nextSong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Guest</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Register</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15008</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538378337000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Guest</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Register</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15002</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538418366000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Guest</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Submit Registration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15002</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538418367000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Guest</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>GET</td>\n",
       "      <td>Register</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15002</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1538419438000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Guest</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>None</td>\n",
       "      <td>PUT</td>\n",
       "      <td>Submit Registration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15002</td>\n",
       "      <td>None</td>\n",
       "      <td>307</td>\n",
       "      <td>1538419439000</td>\n",
       "      <td>None</td>\n",
       "      <td>1261737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist   auth firstName gender  itemInSession lastName  length level  \\\n",
       "0   None  Guest      None   None              5     None     NaN  free   \n",
       "1   None  Guest      None   None              1     None     NaN  free   \n",
       "2   None  Guest      None   None              2     None     NaN  free   \n",
       "3   None  Guest      None   None             12     None     NaN  free   \n",
       "4   None  Guest      None   None             13     None     NaN  free   \n",
       "\n",
       "  location method                 page  registration  sessionId  song  status  \\\n",
       "0     None    GET             Register           NaN      15008  None     200   \n",
       "1     None    GET             Register           NaN      15002  None     200   \n",
       "2     None    PUT  Submit Registration           NaN      15002  None     307   \n",
       "3     None    GET             Register           NaN      15002  None     200   \n",
       "4     None    PUT  Submit Registration           NaN      15002  None     307   \n",
       "\n",
       "              ts userAgent   userId  \n",
       "0  1538378337000      None  1261737  \n",
       "1  1538418366000      None  1261737  \n",
       "2  1538418367000      None  1261737  \n",
       "3  1538419438000      None  1261737  \n",
       "4  1538419439000      None  1261737  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check theory that registration is just a timestamp\n",
    "data_reg = data_raw.where(data_raw['page'].isin({\n",
    "    'Submit Registration',\n",
    "    'Register'\n",
    "}))\n",
    "data_reg = data_reg.limit(5).toPandas()\n",
    "data_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a session ID which features in data_reg\n",
    "session_id = 15002 if use_full_dataset else 1719\n",
    "data_session = data_raw.where(data_raw['sessionId'] == session_id)\n",
    "data_session = data_session.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1538419439000, 1535015137000.0, 1538391976000.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get actual registration time, compare to values in registration column\n",
    "reg_time = data_session.loc[data_session['page'] == 'Submit Registration', 'ts'].values[-1]\n",
    "reg_min = data_session['registration'].min()\n",
    "reg_max = data_session['registration'].max()\n",
    "reg_time, reg_min, reg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('-40 days +14:21:38')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the time difference between actual & recorded registration time\n",
    "reg_time = pd.Timestamp(reg_time, unit='ms')\n",
    "reg_min = pd.Timestamp(reg_min, unit='ms')\n",
    "reg_max = pd.Timestamp(reg_max, unit='ms')\n",
    "reg_min - reg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the session info for evaluation\n",
    "data_session.to_excel('summaries/sample_session.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "<br><i>Registration time is constant when a user is logged in, but it looks like there can be a difference of several days between submitting a registration and the value\n",
    "held in the registration column. Hypothesis is that ts could be sourced from the users device while registration is a timestamp generated by the sparkify system. There could also be a batch process updating the registration field? Will tentatively try using the values in this column.</i>\n",
    "\n",
    "<i>userAgent, userId, location, registration, gender, firstName, lastName can all be filled in based on the sessionId, should improve data availability</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove userId 1261737 from full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_full_dataset:\n",
    "    data_raw = data_raw.withColumn(\n",
    "        'userId',\n",
    "        ssf.when(data_raw['userId'] == 1261737, None).otherwise(data_raw['userId'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in the Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-null values for each session ID\n",
    "data_gapfill = data_raw.groupby('sessionId').agg(\n",
    "    # pylint: disable=no-member\n",
    "    ssf.max('userAgent').alias('userAgent'),\n",
    "    ssf.max('userId').alias('userId'),\n",
    "    ssf.max('location').alias('location'),\n",
    "    ssf.max('registration').alias('registration'),\n",
    "    ssf.max('gender').alias('gender'),\n",
    "    ssf.max('firstName').alias('firstName'),\n",
    "    ssf.max('lastName').alias('lastName')\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these columns from the original dataset\n",
    "data_cleaned = data_raw.drop(\n",
    "    'userAgent', 'userId', 'location', 'registration', 'gender', 'firstName', 'lastName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "      <th>location</th>\n",
       "      <th>registration</th>\n",
       "      <th>gender</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>15002</td>\n",
       "      <td>Judas Priest</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>128</td>\n",
       "      <td>210.12853</td>\n",
       "      <td>paid</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>Living After Midnight</td>\n",
       "      <td>200</td>\n",
       "      <td>1541079909000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1745135</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>1538391976000</td>\n",
       "      <td>M</td>\n",
       "      <td>Kyler</td>\n",
       "      <td>Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>15002</td>\n",
       "      <td>I'm From Barcelona</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>72</td>\n",
       "      <td>175.41179</td>\n",
       "      <td>paid</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>Rec &amp; Play</td>\n",
       "      <td>200</td>\n",
       "      <td>1541069422000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1745135</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>1538391976000</td>\n",
       "      <td>M</td>\n",
       "      <td>Kyler</td>\n",
       "      <td>Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15002</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>18</td>\n",
       "      <td>191.55546</td>\n",
       "      <td>paid</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>Love Me</td>\n",
       "      <td>200</td>\n",
       "      <td>1541061240000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1745135</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>1538391976000</td>\n",
       "      <td>M</td>\n",
       "      <td>Kyler</td>\n",
       "      <td>Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>15002</td>\n",
       "      <td>System of a Down</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>49</td>\n",
       "      <td>164.15302</td>\n",
       "      <td>paid</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>She's Like Heroin</td>\n",
       "      <td>200</td>\n",
       "      <td>1539907218000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1745135</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>1538391976000</td>\n",
       "      <td>M</td>\n",
       "      <td>Kyler</td>\n",
       "      <td>Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>15002</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>42</td>\n",
       "      <td>380.86485</td>\n",
       "      <td>paid</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>Space Dementia</td>\n",
       "      <td>200</td>\n",
       "      <td>1539976852000</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1745135</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>1538391976000</td>\n",
       "      <td>M</td>\n",
       "      <td>Kyler</td>\n",
       "      <td>Wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sessionId              artist       auth  itemInSession     length level  \\\n",
       "143      15002        Judas Priest  Logged In            128  210.12853  paid   \n",
       "87       15002  I'm From Barcelona  Logged In             72  175.41179  paid   \n",
       "41       15002       Justin Bieber  Logged In             18  191.55546  paid   \n",
       "232      15002    System of a Down  Logged In             49  164.15302  paid   \n",
       "302      15002                Muse  Logged In             42  380.86485  paid   \n",
       "\n",
       "    method      page                   song  status             ts  \\\n",
       "143    PUT  NextSong  Living After Midnight     200  1541079909000   \n",
       "87     PUT  NextSong             Rec & Play     200  1541069422000   \n",
       "41     PUT  NextSong                Love Me     200  1541061240000   \n",
       "232    PUT  NextSong      She's Like Heroin     200  1539907218000   \n",
       "302    PUT  NextSong         Space Dementia     200  1539976852000   \n",
       "\n",
       "                                             userAgent   userId  \\\n",
       "143  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1745135   \n",
       "87   Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1745135   \n",
       "41   Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1745135   \n",
       "232  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1745135   \n",
       "302  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1745135   \n",
       "\n",
       "                                 location   registration gender firstName  \\\n",
       "143  Riverside-San Bernardino-Ontario, CA  1538391976000      M     Kyler   \n",
       "87   Riverside-San Bernardino-Ontario, CA  1538391976000      M     Kyler   \n",
       "41   Riverside-San Bernardino-Ontario, CA  1538391976000      M     Kyler   \n",
       "232  Riverside-San Bernardino-Ontario, CA  1538391976000      M     Kyler   \n",
       "302  Riverside-San Bernardino-Ontario, CA  1538391976000      M     Kyler   \n",
       "\n",
       "    lastName  \n",
       "143     Wall  \n",
       "87      Wall  \n",
       "41      Wall  \n",
       "232     Wall  \n",
       "302     Wall  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge back to ensure fields are fully populated\n",
    "data_cleaned = data_cleaned.join(data_gapfill, on='sessionId', how='inner')\n",
    "data_cleaned.where(data_raw['sessionId'] == session_id).toPandas().sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get platform from user agent string\n",
    "platform_getter = ssf.regexp_extract(\n",
    "    data_cleaned['userAgent'],\n",
    "    r'[\\w\\/\\.]+ \\(([\\w\\s\\.]+);.*\\)',\n",
    "    1\n",
    ")\n",
    "\n",
    "data_cleaned = data_cleaned.withColumn('platform', platform_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring through the state code as a field\n",
    "def extract_state(location):\n",
    "    '''Extract the state code from the location. If multiple state codes are\n",
    "    given then just take the last one. This seems to happen when the location\n",
    "    falls within a metropolitan area which crosses state lines.\n",
    "    \n",
    "    Sample locations:\n",
    "    Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\n",
    "    Dallas-Fort Worth-Arlington, TX\n",
    "    '''\n",
    "\n",
    "    if not isinstance(location, str):\n",
    "        return None\n",
    "    state = location.split(',')[-1]\n",
    "    state = state.split('-')[-1].strip()\n",
    "    return state\n",
    "\n",
    "state_getter = ssf.udf(extract_state, sst.StringType())\n",
    "data_cleaned = data_cleaned.withColumn('state', state_getter('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up song names\n",
    "\n",
    "def extract_song(song):\n",
    "    '''Standardize song title cases and remove any extra tags.\n",
    "    \n",
    "    Example:\n",
    "    Song Title [feat. artist] (Album Version) -->  SONG TITLE'''\n",
    "\n",
    "    if not isinstance(song, str):\n",
    "        return None\n",
    "\n",
    "    # Remove any bracketed tags\n",
    "    song = re.sub(r' \\[.+\\]', '', song)\n",
    "    song = re.sub(r' \\(.+\\)', '', song)\n",
    "\n",
    "    # Remove any non-standard characters\n",
    "    song = re.sub(r'[^\\w\\s]+', '', song)\n",
    "\n",
    "    # Fix any duplicated spaces\n",
    "    song = re.sub(r'\\s\\s+', ' ', song)\n",
    "\n",
    "    # Standardize case, remove trailing whitespace\n",
    "    song = song.strip().upper()\n",
    "    return song\n",
    "\n",
    "song_getter = ssf.udf(extract_song, sst.StringType())\n",
    "data_cleaned = data_cleaned.withColumn('songCleaned', song_getter('song'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Please note that between this section and \"Feature Engineering\", the majority of tables defined will not be reused. They are used for the sole purpose of generating summary charts/tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the exact moment a customer churns\n",
    "data_cleaned = data_cleaned.withColumn(\n",
    "    'churnFlag',\n",
    "    ssf.when(data_cleaned['page'] == 'Cancellation Confirmation', 1).otherwise(0)\n",
    ").withColumn(\n",
    "    'downgradeFlag',\n",
    "    ssf.when(data_cleaned['page'] == 'Submit Downgrade', 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag all records corresponding to a churned customer\n",
    "churned = data_cleaned.where(data_cleaned['churnFlag'] == 1).select('userId').distinct()\n",
    "churned = churned.toPandas()['userId'].tolist() # Potentially risky for truly \"big\" data\n",
    "data_cleaned = data_cleaned.withColumn(\n",
    "    'userChurnFlag',\n",
    "    ssf.when(data_cleaned['userId'].isin(*churned), 1).otherwise(0))\n",
    "\n",
    "data_cleaned = data_cleaned.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Counts\n",
    "user_stats = data_cleaned.groupby('userChurnFlag', 'userId').agg(\n",
    "    #pylint: disable=no-member\n",
    "    ssf.countDistinct('artist').alias('noArtists'),\n",
    "    ssf.countDistinct('songCleaned').alias('noSongs'),\n",
    "    ssf.count('songCleaned').alias('noPlays'),\n",
    "    ssf.max('gender').alias('gender'),\n",
    "    ssf.max('state').alias('state'),\n",
    "    ssf.max('registration').alias('registration'),\n",
    "    ssf.mean('length').alias('meanSongLength')\n",
    ")\n",
    "user_stats = user_stats.toPandas()\n",
    "user_stats.loc[:, 'registration'] = user_stats['registration'].map(\n",
    "    lambda x: pd.Timestamp(x, unit='ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Items in Session\n",
    "item_stats = data_cleaned.groupby('userChurnFlag', 'sessionId').agg(\n",
    "    #pylint: disable=no-member\n",
    "    ssf.max('itemInSession').alias('sessionLength'),\n",
    "    ssf.max('platform').alias('platform')\n",
    ")\n",
    "item_stats = item_stats.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page visits\n",
    "page_stats = data_cleaned.groupby('userChurnFlag', 'page').count()\n",
    "page_stats = page_stats.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status codes\n",
    "status_stats = data_cleaned.groupby('userChurnFlag', 'status').count()\n",
    "status_stats = status_stats.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple counts (continuous)\n",
    "id_cols = {'userChurnFlag', 'userId'}\n",
    "cat_cols = {'gender', 'state'}\n",
    "for user_col in [x for x in user_stats.columns if x not in id_cols.union(cat_cols)]:\n",
    "    fig = px.histogram(\n",
    "        user_stats,\n",
    "        x=user_col,\n",
    "        color='userChurnFlag',\n",
    "        barmode='overlay',\n",
    "        histnorm='percent',\n",
    "        labels={0: 'No Churn', 1: 'Churn'},\n",
    "        nbins=50\n",
    "        )\n",
    "    fig.write_html(f'figures/{user_col}StatsPerc.html')\n",
    "\n",
    "    fig = px.histogram(\n",
    "        user_stats,\n",
    "        x=user_col,\n",
    "        color='userChurnFlag',\n",
    "        barmode='overlay',\n",
    "        labels={0: 'No Churn', 1: 'Churn'},\n",
    "        nbins=50)\n",
    "    fig.write_html(f'figures/{user_col}StatsAbs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple counts (discrete)\n",
    "group_counts = user_stats.groupby('userChurnFlag').agg(\n",
    "    totalUsers = ('userId', 'nunique')\n",
    ").reset_index()\n",
    "for user_col in cat_cols:\n",
    "    plot_df = user_stats.groupby(['userChurnFlag', user_col]).agg(\n",
    "        noUsers = ('userId', 'nunique')\n",
    "    ).reset_index()\n",
    "    plot_df = plot_df.merge(group_counts, on='userChurnFlag', how='inner')\n",
    "    plot_df.loc[:, 'percUsers'] = plot_df['noUsers'] / plot_df['totalUsers']\n",
    "    plot_df = plot_df.sort_values(by='noUsers', ascending=False)\n",
    "    plot_df.loc[:, 'userChurnFlag'] = plot_df['userChurnFlag'].astype(bool)\n",
    "\n",
    "    fig = px.bar(\n",
    "        plot_df,\n",
    "        x=user_col,\n",
    "        y='percUsers',\n",
    "        color='userChurnFlag',\n",
    "        barmode='group',\n",
    "        labels={True: 'Churn', False: 'No Churn'}\n",
    "    )\n",
    "    fig.write_html(f'figures/{user_col}StatsPerc.html')\n",
    "\n",
    "    fig = px.bar(\n",
    "        plot_df,\n",
    "        x=user_col,\n",
    "        y='noUsers',\n",
    "        color='userChurnFlag',\n",
    "        barmode='group',\n",
    "        labels={True: 'Churn', False: 'No Churn'}\n",
    "    )\n",
    "    fig.write_html(f'figures/{user_col}StatsAbs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session length\n",
    "fig = px.histogram(\n",
    "    item_stats,\n",
    "    x='sessionLength',\n",
    "    color='userChurnFlag',\n",
    "    barmode='overlay',\n",
    "    histnorm='percent',\n",
    "    labels={0: 'No Churn', 1: 'Churn'},\n",
    "    nbins=50)\n",
    "fig.write_html('figures/sessionLengthStatsPerc.html')\n",
    "\n",
    "fig = px.histogram(\n",
    "    item_stats,\n",
    "    x='sessionLength',\n",
    "    color='userChurnFlag',\n",
    "    barmode='overlay',\n",
    "    labels={0: 'No Churn', 1: 'Churn'},\n",
    "    nbins=50)\n",
    "fig.write_html('figures/sessionLengthStatsAbs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform\n",
    "fig = px.histogram(\n",
    "    item_stats,\n",
    "    x='platform',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    "    histnorm='percent',\n",
    "    labels={0: 'No Churn', 1: 'Churn'}\n",
    ")\n",
    "fig.write_html('figures/platformStatsPerc.html')\n",
    "\n",
    "fig = px.histogram(\n",
    "    item_stats,\n",
    "    x='platform',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    "    labels={0: 'No Churn', 1: 'Churn'}\n",
    ")\n",
    "fig.write_html('figures/platformStatsAbs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page visits\n",
    "page_stats.loc[:, 'userChurnFlag'] = page_stats['userChurnFlag'].astype(bool)\n",
    "group_sums = page_stats.groupby('userChurnFlag').agg(\n",
    "    totalVisits = ('count', 'sum')\n",
    ").reset_index()\n",
    "page_stats = page_stats.merge(group_sums, on='userChurnFlag', how='inner')\n",
    "page_stats.loc[:, 'percentage'] = page_stats['count'] / page_stats['totalVisits']\n",
    "page_stats = page_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    page_stats,\n",
    "    x='page',\n",
    "    y='count',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    ")\n",
    "fig.write_html('figures/pageStatsAbs.html')\n",
    "\n",
    "fig = px.bar(\n",
    "    page_stats,\n",
    "    x='page',\n",
    "    y='percentage',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    ")\n",
    "fig.write_html('figures/pageStatsPerc.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status codes\n",
    "status_stats.loc[:, 'userChurnFlag'] = status_stats['userChurnFlag'].astype(bool)\n",
    "group_sums = status_stats.groupby('userChurnFlag').agg(\n",
    "    totalResponses = ('count', 'sum')\n",
    ").reset_index()\n",
    "status_stats = status_stats.merge(group_sums, on='userChurnFlag', how='inner')\n",
    "status_stats.loc[:, 'percentage'] = status_stats['count'] / status_stats['totalResponses']\n",
    "status_stats = status_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    status_stats,\n",
    "    x='status',\n",
    "    y='count',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    ")\n",
    "fig.write_html('figures/statusStatsAbs.html')\n",
    "\n",
    "fig = px.bar(\n",
    "    status_stats,\n",
    "    x='status',\n",
    "    y='percentage',\n",
    "    color='userChurnFlag',\n",
    "    barmode='group',\n",
    ")\n",
    "fig.write_html('figures/statusStatsPerc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger evaluation of the datset up to this point\n",
    "data_cleaned = data_cleaned.orderBy(\n",
    "    'userID', 'ts', ascending=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static variables (no time dependency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate these measures using the full range of data\n",
    "static_vars = data_cleaned.groupby('userId').agg(\n",
    "    #pylint: disable=no-member\n",
    "    ssf.max('gender').alias('gender'),\n",
    "    ssf.max('ts').alias('lastTs'),\n",
    "    ssf.min('registration').alias('registration'),\n",
    "    ssf.max('state').alias('state'),\n",
    "    ssf.max('churnFlag').alias('userChurnFlag')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the current age of each account\n",
    "static_vars = static_vars.withColumn(\n",
    "    'accountAge',\n",
    "    static_vars['lastTs']-static_vars['registration'])\n",
    "\n",
    "static_vars = static_vars.drop('lastTs', 'registration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Variables (to be evaluated over multiple time windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modal_system(data_in, name):\n",
    "    '''For the provided subset of data, work out the most frequently used\n",
    "    system for each userId. Rename this derived \"platform\" column, appending it\n",
    "    with the provided value for \"name\".'''\n",
    "\n",
    "    sys_counts = data_in.groupby('userId', 'platform').agg(\n",
    "        ssf.countDistinct('sessionId').alias('noSessions'))\n",
    "\n",
    "    # No built-in mode function, need to manually rank using window functions\n",
    "    # Using row_number rather than rank to avoid ties\n",
    "    usr_window = ssw.Window.partitionBy(\n",
    "        sys_counts['userId']\n",
    "    ).orderBy(\n",
    "        sys_counts['noSessions'].desc()\n",
    "    )\n",
    "    sys_counts = sys_counts.withColumn(\n",
    "        #pylint: disable=no-member\n",
    "        'platformRank', ssf.row_number().over(usr_window)\n",
    "    )\n",
    "\n",
    "    # Take first ranked platform for each \n",
    "    sys_modal = sys_counts.where(\n",
    "        sys_counts['platformRank'] == 1\n",
    "    ).select(\n",
    "        'userId', f'platform'\n",
    "    )\n",
    "\n",
    "    sys_modal = sys_modal.withColumnRenamed('platform', f'platform{name}')\n",
    "\n",
    "    return sys_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_aggregates(data_in, name):\n",
    "    '''For the provided subset of data, derive all features which can be calculated\n",
    "    using the built-in pyspark aggregation functions. Append all derived field names\n",
    "    with the provided value for \"name\".'''\n",
    "    \n",
    "    # Integer flag for http errors returned\n",
    "    flagged = data_in.withColumn(\n",
    "        'httpError',\n",
    "        ssf.when(data_in['status']==404, 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # Perform various aggregations at a userId level\n",
    "    dynamic_vars = flagged.groupby(\n",
    "        'userId'\n",
    "    ).agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.count('platform').alias(f'noPlatforms{name}'),\n",
    "        ssf.count('userAgent').alias(f'noSystems{name}'),\n",
    "        ssf.sum('httpError').alias(f'httpErrors{name}'),\n",
    "        ssf.countDistinct('artist').alias(f'noArtists{name}'),\n",
    "        ssf.countDistinct('songCleaned').alias(f'noSongs{name}'),\n",
    "        # Count excludes nulls, so this should be equivalent to counting\n",
    "        # number of nextSong pages\n",
    "        ssf.count('songCleaned').alias(f'noPlays{name}'),\n",
    "        ssf.first('level').alias(f'levelStart{name}'),\n",
    "        ssf.last('level').alias(f'levelEnd{name}')\n",
    "    )\n",
    "\n",
    "    return dynamic_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_stats(data_in, name):\n",
    "    '''For the provided subset of data, derive some more complex features relating\n",
    "    to session/song length. Append all derived field names with the provided value\n",
    "    for \"name\".'''\n",
    "\n",
    "    # Limit to song plays\n",
    "    session_vars = data_in.filter(data_in['page'] == 'NextSong')\n",
    "\n",
    "    # For each song, bring through the start of the next song\n",
    "    session_window = ssw.Window.partitionBy(\n",
    "        session_vars['userId'], session_vars['sessionId']\n",
    "    ).orderBy(\n",
    "        'ts'\n",
    "    )\n",
    "    session_vars = session_vars.withColumn(\n",
    "        'nextPlayStart',\n",
    "        ssf.lead(session_vars['ts']).over(session_window)\n",
    "    )\n",
    "\n",
    "    # Use this data to calculate the play time for each song\n",
    "    session_vars = session_vars.withColumn(\n",
    "        'playTime',\n",
    "        session_vars['nextPlayStart'] - session_vars['ts']\n",
    "    )\n",
    "\n",
    "    # Get total play time for each session\n",
    "    session_vars = session_vars.groupby(\n",
    "        'userId', 'sessionId'\n",
    "    ).agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.sum('playTime').alias('sessionLength')\n",
    "    )\n",
    "\n",
    "    # Get play time stats for each user\n",
    "    session_vars = session_vars.groupby(\n",
    "        'userId'\n",
    "    ).agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.mean('sessionLength').alias(f'lengthMean{name}'),\n",
    "        ssf.stddev('sessionLength').alias(f'lengthStd{name}'),\n",
    "        ssf.sum('sessionLength').alias(f'lengthSum{name}')\n",
    "    )\n",
    "\n",
    "    return session_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popularity_scores(data_in, name):\n",
    "    '''Attempts to create a metric showing how popular the music each user listens\n",
    "    to is. This metric is calculated for the provided subset of data, and the\n",
    "    generated popularityScore field is appended with the provided value of \"name\".'''\n",
    "    \n",
    "    # Select song plays only\n",
    "    song_data = data_in.filter(data_in['page'] == 'NextSong')\n",
    "\n",
    "    # For each song, calculate the total number of plays\n",
    "    song_totals = song_data.groupby('songCleaned').agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.count('ts').alias('songTotal')\n",
    "    )\n",
    "    \n",
    "    # Calculate the number of plays across all songs\n",
    "    overall_total = song_totals.agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.sum('songTotal').alias('overallTotal')\n",
    "    ).collect()[0]['overallTotal']\n",
    "\n",
    "    # For each song, how much does it contribute towards the total play count?\n",
    "    song_totals = song_totals.withColumn(\n",
    "        'overallPerc',\n",
    "        song_totals['songTotal'] / overall_total\n",
    "    ).select(\n",
    "        'songCleaned', 'overallPerc'\n",
    "    )\n",
    "\n",
    "    # Restrict input dataset to only relevant fields\n",
    "    popularity = song_data.select('userId', 'songCleaned')\n",
    "\n",
    "    # Make a clone of popularity, bug in pyspark causes errors if this isn't done\n",
    "    # https://stackoverflow.com/questions/45713290/how-to-resolve-the-analysisexception-resolved-attributes-in-spark\n",
    "    popularity = spark.createDataFrame(popularity.rdd, popularity.schema)\n",
    "\n",
    "    # Join on popularity scores for each song listened to\n",
    "    popularity = popularity.join(\n",
    "        song_totals,\n",
    "        popularity['songCleaned']==song_totals['songCleaned'],\n",
    "        how='left')\n",
    "    \n",
    "    # For each user, how 'popular' is the music they listen to?\n",
    "    # As popularity was not created using SELECT DISTINCT this metric\n",
    "    # is weighted according to the number of plays for each song.\n",
    "    popularity = popularity.groupby('userId').agg(\n",
    "        #pylint: disable=no-member\n",
    "        ssf.sum('overallPerc').alias(f'popularityScore{name}')\n",
    "    )\n",
    "\n",
    "    return popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_clicks(data_in, name):\n",
    "    '''Calculate the number of times each user has clicked through to each page in\n",
    "    the provided subset of data. All generated field names are appended with the\n",
    "    provided value of \"name\".\n",
    "    \n",
    "    This function is not currently used, as I decided to avoid the use of the\n",
    "    pivot operation while debugging memory issues.'''\n",
    "\n",
    "    def format_page(page):\n",
    "        '''Remove spaces, append value of name to each page to ensure\n",
    "        it appears in column headers after the pivot operation.'''\n",
    "\n",
    "        if not isinstance(page, str):\n",
    "            return None\n",
    "        \n",
    "        page = page.replace(' ', '')\n",
    "        page = f'{page}{name}'\n",
    "        return page\n",
    "    \n",
    "    page_getter = ssf.udf(format_page, sst.StringType())\n",
    "\n",
    "    # Process all page names\n",
    "    page_clicks = data_in.withColumn('page', page_getter('page'))\n",
    "\n",
    "    # Perform the pivot/aggregation\n",
    "    page_clicks = page_clicks.groupby('userId').pivot('page').count()\n",
    "\n",
    "    # List of all pages which should be accounted for\n",
    "    included_pages = [\n",
    "        'About', 'Add Friend', 'Add to Playlist', 'Downgrade',\n",
    "        'Error', 'Help', 'Home', 'Login', 'Logout', 'NextSong', 'Register',\n",
    "        'Roll Advert', 'Save Settings', 'Settings', 'Submit Downgrade', 'Submit Registration',\n",
    "        'Submit Upgrade', 'Thumbs Down', 'Thumbs Up', 'Upgrade'\n",
    "    ]\n",
    "\n",
    "    # Generate final list of field names\n",
    "    included_pages = ['userId'] + [format_page(x) for x in included_pages]\n",
    "\n",
    "    # And which ones didn't\n",
    "    missing_pages = [x for x in included_pages if x not in page_clicks.columns]\n",
    "\n",
    "    # Add a column of 0s for any missing pages\n",
    "    for missing_page in missing_pages:\n",
    "        page_clicks = page_clicks.withColumn(\n",
    "            #pylint: disable=no-member\n",
    "            missing_page,\n",
    "            ssf.lit(0)\n",
    "        )\n",
    "\n",
    "    # Ensure the output always has consistent headers\n",
    "    page_clicks = page_clicks.select(*included_pages)\n",
    "\n",
    "    return page_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_clicks_alt(data_in, name):\n",
    "    '''Calculate the number of times each user has clicked through to each page in\n",
    "    the provided subset of data. All generated field names are appended with the\n",
    "    provided value of \"name\".\n",
    "    \n",
    "    Alternate form of get_page_clicks, avoids use of the pivot function to\n",
    "    (hopefully) allow the code to run when using the full dataset. In theory the\n",
    "    output of this function should be the same as the original get_page_clicks.'''\n",
    "\n",
    "    # List of all pages which should be accounted for\n",
    "    # - Note that cancellation submission is not included, as this would result\n",
    "    #   in a proxy column that contains the target label\n",
    "    included_pages = [\n",
    "        'About', 'Add Friend', 'Add to Playlist', 'Downgrade',\n",
    "        'Error', 'Help', 'Home', 'Login', 'Logout', 'NextSong', 'Register',\n",
    "        'Roll Advert', 'Save Settings', 'Settings', 'Submit Downgrade', 'Submit Registration',\n",
    "        'Submit Upgrade', 'Thumbs Down', 'Thumbs Up', 'Upgrade'\n",
    "    ]\n",
    "\n",
    "    def format_page(page):\n",
    "        '''Remove spaces, append value of name to each page to ensure\n",
    "        it appears in column headers after the pivot operation.'''\n",
    "        if not isinstance(page, str):\n",
    "            return None\n",
    "        \n",
    "        page = page.replace(' ', '')\n",
    "        page = f'{page}{name}'\n",
    "        return page\n",
    "    \n",
    "    page_getter = ssf.udf(format_page, sst.StringType())\n",
    "\n",
    "    # Process all page names in the data\n",
    "    page_clicks = data_in.withColumn('page', page_getter('page'))\n",
    "    \n",
    "    # Apply the same transformation to the list of expected page names\n",
    "    included_pages = [format_page(x) for x in included_pages]\n",
    "\n",
    "    # Select only data pertaining to pages visited by a user\n",
    "    page_clicks = page_clicks.select('userId', 'page').dropna(how='any')\n",
    "\n",
    "    # Add new field for count of each page\n",
    "    for included_page in included_pages:\n",
    "        page_clicks = page_clicks.withColumn(\n",
    "            included_page,\n",
    "            ssf.when(page_clicks['page'] == included_page, 1).otherwise(0)\n",
    "        )\n",
    "    \n",
    "    # Set up list of aggregations required to calculate the number\n",
    "    # of visits to each page\n",
    "    aggregations = [\n",
    "        #pylint: disable=no-member\n",
    "        ssf.sum(col).alias(col)\n",
    "        for col in included_pages\n",
    "    ]\n",
    "\n",
    "    # Apply this list of aggregations for each userId\n",
    "    page_clicks = page_clicks.groupby('userId').agg(*aggregations)\n",
    "\n",
    "    return page_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate aggregate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max timestamp\n",
    "limits = data_cleaned.agg(\n",
    "    #pylint: disable=no-member\n",
    "    ssf.max('ts').alias('maxTs'),\n",
    "    ssf.min('ts').alias('minTs')\n",
    ").collect()[0]\n",
    "max_ts = limits['maxTs']\n",
    "min_ts = limits['minTs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factors to convert to/from timestamps and days/weeks/months\n",
    "day_delta = 24 * 60 * 60 * 1000\n",
    "week_delta = 7 * day_delta\n",
    "month_delta = 31 * day_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9677423088410992"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many months of data do we have?\n",
    "(max_ts - min_ts) / month_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of date ranges over which all 'dynamic'\n",
    "# measures will be evaluated. The keys are simply aliases which\n",
    "# will be passed to the \"name\" parameter of the functions defined above.\n",
    "# This ensures measures have distinct field names between iterations.\n",
    "start_times = {\n",
    "    'Week': max_ts - week_delta,\n",
    "    'Month': max_ts - month_delta\n",
    "}\n",
    "\n",
    "# More data is available in the full dataset\n",
    "if use_full_dataset:\n",
    "    start_times['TwoMonth'] = max_ts - 2*month_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate these 'dynamic' measures over each of the specified date ranges\n",
    "\n",
    "# Container for the output from each iteration\n",
    "outputs = None\n",
    "\n",
    "for name, start_ts in start_times.items():\n",
    "\n",
    "    # Select only data from after the start time\n",
    "    data_subset = data_cleaned.where(\n",
    "        data_cleaned['ts'] >= start_ts\n",
    "    ).persist()\n",
    "\n",
    "    # Calculate all measures using functions defined above\n",
    "    modal_system = get_modal_system(data_subset, name)\n",
    "    simple_aggregates = get_simple_aggregates(data_subset, name)\n",
    "    session_stats = get_session_stats(data_subset, name)\n",
    "    popularity_scores = get_popularity_scores(data_subset, name)\n",
    "    page_clicks = get_page_clicks_alt(data_subset, name)\n",
    "\n",
    "    # Join all of the generated datasets together\n",
    "    merged = modal_system.join(\n",
    "        simple_aggregates,\n",
    "        on='userId',\n",
    "        how='full_outer'\n",
    "    ).join(\n",
    "        session_stats,\n",
    "        on='userId',\n",
    "        how='full_outer'\n",
    "    ).join(\n",
    "        popularity_scores,\n",
    "        on='userId',\n",
    "        how='full_outer'\n",
    "    ).join(\n",
    "        page_clicks,\n",
    "        on='userId',\n",
    "        how='full_outer'\n",
    "    ).persist()\n",
    "\n",
    "    # Add the joined dataset to the final output\n",
    "    if outputs is None:\n",
    "        outputs = merged\n",
    "    else:\n",
    "        outputs = outputs.join(merged, on='userId', how='full_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, join the static measures back in\n",
    "merged = static_vars.join(\n",
    "    outputs,\n",
    "    on='userId',\n",
    "    how='full_outer'\n",
    ")\n",
    "\n",
    "# # Fill in empty platform data with 'unknown'\n",
    "# platform_cols = [x for x in outputs.columns if 'platform' in x]\n",
    "# merged = merged.fillna('unknown', subset=platform_cols)\n",
    "\n",
    "# # Fill in empty level data with 'free'\n",
    "# level_cols = [x for x in outputs.columns if 'level' in x]\n",
    "# merged = merged.fillna('free', subset=level_cols)\n",
    "\n",
    "# # Fill in any other empty values with 0\n",
    "# merged = merged.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_string(string_in, fill_value='unknown'):\n",
    "    '''A simple function which fills in missing values in a categorical field.'''\n",
    "\n",
    "    if not isinstance(string_in, str):\n",
    "        return fill_value\n",
    "    elif not string_in:\n",
    "        return fill_value\n",
    "    else:\n",
    "        return string_in\n",
    "\n",
    "na_handler = ssf.udf(fill_empty_string, sst.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical values with numerical IDs for each category\n",
    "\n",
    "# Get a list of categorical columns in the dataset\n",
    "# - Needed as some of these will appear in multiple columns (one for each named period)\n",
    "cat_cols = ['gender', 'state', 'platform', 'level']\n",
    "cat_cols = [x for x in merged.columns if any((y for y in cat_cols if y in x))]\n",
    "\n",
    "indexers = {}\n",
    "for cat_col in cat_cols:\n",
    "    # Fill in any null values\n",
    "    merged = merged.withColumn(cat_col, na_handler(cat_col))\n",
    "    \n",
    "    # Train a string indexer which generates mappings for each category to\n",
    "    # a corresponding numerical ID\n",
    "    indexer = smf.StringIndexer(\n",
    "        inputCol=cat_col,\n",
    "        outputCol=f\"{cat_col}Inx\"\n",
    "    )\n",
    "    indexer = indexer.fit(merged)\n",
    "    \n",
    "    # Apply the indexer to the dataset, drop the original column\n",
    "    merged = indexer.transform(merged)\n",
    "    merged = merged.drop(cat_col).withColumnRenamed(f\"{cat_col}Inx\", cat_col)\n",
    "    \n",
    "    # Save the indexer object for future reference\n",
    "    indexers[cat_col] = indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in any remaining null values, as they must correspond to numerical features\n",
    "merged = merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on all categorical features\n",
    "encoder = smf.OneHotEncoder(\n",
    "    inputCols=cat_cols,\n",
    "    outputCols=[f\"{x}Vec\" for x in cat_cols]\n",
    ")\n",
    "encoder = encoder.fit(merged)\n",
    "encoded = encoder.transform(merged)\n",
    "encoded = encoded.drop(*cat_cols)\n",
    "\n",
    "encoded = encoded.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000280</td>\n",
       "      <td>0</td>\n",
       "      <td>(2963223000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002185</td>\n",
       "      <td>0</td>\n",
       "      <td>(5680891000.0, 361.0, 361.0, 1.0, 266.0, 290.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030587</td>\n",
       "      <td>0</td>\n",
       "      <td>(11370026000.0, 365.0, 365.0, 0.0, 270.0, 292....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1033297</td>\n",
       "      <td>0</td>\n",
       "      <td>(10034889000.0, 204.0, 204.0, 0.0, 146.0, 157....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057724</td>\n",
       "      <td>0</td>\n",
       "      <td>(8298249000.0, 613.0, 613.0, 0.0, 417.0, 479.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  label                                           features\n",
       "0  1000280      0  (2963223000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...\n",
       "1  1002185      0  (5680891000.0, 361.0, 361.0, 1.0, 266.0, 290.0...\n",
       "2  1030587      0  (11370026000.0, 365.0, 365.0, 0.0, 270.0, 292....\n",
       "3  1033297      0  (10034889000.0, 204.0, 204.0, 0.0, 146.0, 157....\n",
       "4  1057724      0  (8298249000.0, 613.0, 613.0, 0.0, 417.0, 479.0..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use VectorAssembler to combine all features into a single vector\n",
    "feature_cols = [x for x in encoded.columns if x not in {'userId', 'userChurnFlag'}]\n",
    "assembler = smf.VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol='features')\n",
    "encoded = assembler.transform(encoded)\n",
    "encoded = encoded.drop(*feature_cols)\n",
    "encoded = encoded.withColumnRenamed('userChurnFlag', 'label')\n",
    "encoded = encoded.persist()\n",
    "\n",
    "# Check the format of the final dataset\n",
    "encoded_sample = encoded.limit(5).toPandas()\n",
    "encoded_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out validation dataset\n",
    "train, val = encoded.randomSplit([3.0, 1.0], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up scaler for numerical features\n",
    "scaler = smf.StandardScaler(\n",
    "    withStd=True,\n",
    "    withMean=False,\n",
    "    inputCol='features',\n",
    "    outputCol='scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensionality of scaled vectors\n",
    "reducer = smf.PCA(\n",
    "    k=10,\n",
    "    inputCol=scaler.getOutputCol(),\n",
    "    outputCol='selectedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classifier to generate the final predictions\n",
    "classifier = smc.GBTClassifier(\n",
    "    labelCol='label',\n",
    "    featuresCol=reducer.getOutputCol(),\n",
    "    predictionCol='predictedLabel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all steps in a pipeline\n",
    "pipeline = sm.Pipeline(\n",
    "    stages=[scaler, reducer, classifier]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an evaluator which will quantify model performance\n",
    "eval_f1 = sme.MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='predictedLabel',\n",
    "    metricName='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a parameter grid for cross validation\n",
    "param_grid = smt.ParamGridBuilder().addGrid(\n",
    "    # Number of features to generate\n",
    "    reducer.k, [25, 50, 75, 100]\n",
    ").addGrid(\n",
    "    classifier.maxDepth, [3, 5, 10]\n",
    ").addGrid(\n",
    "    classifier.subsamplingRate, [0.1, 0.2, 0.3]\n",
    ").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring everything together\n",
    "validator = smt.CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=eval_f1,\n",
    "    numFolds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to data\n",
    "model = validator.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('final_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.transform(train)\n",
    "val_predictions = model.transform(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='PCA_ffcc51f04dd9', name='k', doc='the number of principal components'): 25,\n",
       " Param(parent='GBTClassifier_939da222e149', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='GBTClassifier_939da222e149', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.3}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the selected model parameters\n",
    "model.getEstimatorParamMaps()[np.argmax(model.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.82\n",
      "Validation F1: 0.80\n"
     ]
    }
   ],
   "source": [
    "train_f1 = eval_f1.evaluate(train_predictions)\n",
    "val_f1 = eval_f1.evaluate(val_predictions)\n",
    "print(f\"Train F1: {train_f1:,.2f}\\nValidation F1: {val_f1:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.85\n",
      "Validation AUC: 0.81\n"
     ]
    }
   ],
   "source": [
    "eval_roc = sme.BinaryClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    rawPredictionCol='probability',\n",
    "    metricName='areaUnderROC'\n",
    ")\n",
    "\n",
    "train_auc = eval_roc.evaluate(train_predictions)\n",
    "val_auc = eval_roc.evaluate(val_predictions)\n",
    "print(f\"Train AUC: {train_auc:,.2f}\\nValidation AUC: {val_auc:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.84\n",
      "Validation Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "eval_accuracy = sme.MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='predictedLabel',\n",
    "    metricName='accuracy'\n",
    ")\n",
    "\n",
    "train_acc = eval_accuracy.evaluate(train_predictions)\n",
    "val_acc = eval_accuracy.evaluate(val_predictions)\n",
    "print(f\"Train Accuracy: {train_acc:,.2f}\\nValidation Accuracy: {val_acc:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.82\n",
      "Validation Precision: 0.80\n"
     ]
    }
   ],
   "source": [
    "eval_precision = sme.MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='predictedLabel',\n",
    "    metricName='weightedPrecision'\n",
    ")\n",
    "\n",
    "train_prec = eval_precision.evaluate(train_predictions)\n",
    "val_prec = eval_precision.evaluate(val_predictions)\n",
    "print(f\"Train Precision: {train_prec:,.2f}\\nValidation Precision: {val_prec:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.84\n",
      "Validation Recall: 0.81\n"
     ]
    }
   ],
   "source": [
    "eval_recall = sme.MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='predictedLabel',\n",
    "    metricName='weightedRecall'\n",
    ")\n",
    "\n",
    "train_rec = eval_recall.evaluate(train_predictions)\n",
    "val_rec = eval_recall.evaluate(val_predictions)\n",
    "print(f\"Train Recall: {train_rec:,.2f}\\nValidation Recall: {val_rec:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices for each dataset\n",
    "trn_res_df = train_predictions.select('label', 'predictedLabel').toPandas()\n",
    "trn_cmat = confusion_matrix(\n",
    "    y_true=trn_res_df['label'],\n",
    "    y_pred=trn_res_df['predictedLabel'])\n",
    "\n",
    "\n",
    "val_res_df = val_predictions.select('label', 'predictedLabel').toPandas()\n",
    "val_cmat = confusion_matrix(\n",
    "    y_true=val_res_df['label'],\n",
    "    y_pred=val_res_df['predictedLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training confusion matrix\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    trn_cmat,\n",
    "    colorscale='haline',\n",
    "    x=['No Churn', 'Churn'],\n",
    "    y=['No Churn', 'Churn'])\n",
    "fig.update_xaxes(side='bottom', title='Predicted Label')\n",
    "fig.update_yaxes(title='Actual Label')\n",
    "fig.update_layout(title='Confusion Matrix - Training Dataset')\n",
    "fig.write_html('figures/cmat_train.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation confusion matrix\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    val_cmat,\n",
    "    colorscale='haline',\n",
    "    x=['No Churn', 'Churn'],\n",
    "    y=['No Churn', 'Churn'])\n",
    "fig.update_xaxes(side='bottom', title='Predicted Label')\n",
    "fig.update_yaxes(title='Actual Label')\n",
    "fig.update_layout(title='Confusion Matrix - Validation Dataset')\n",
    "fig.write_html('figures/cmat_val.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we do better by working out the optimal cutoff point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_score, accuracy_score, recall_score\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_pred_df = train_predictions.select('userId', 'probability', 'label', 'predictedLabel').toPandas()\n",
    "val_pred_df = val_predictions.select('userId', 'probability', 'label', 'predictedLabel').toPandas()\n",
    "\n",
    "trn_pred_df.to_csv('data/train_predictions.csv', index=False)\n",
    "val_pred_df.to_csv('data/val_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_df.loc[:, 'churnProba'] = val_pred_df['probability'].map(lambda x: x[-1])\n",
    "trn_pred_df.loc[:, 'churnProba'] = trn_pred_df['probability'].map(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fpr, trn_tpr, trn_thresholds = roc_curve(trn_pred_df['label'], trn_pred_df['churnProba'])\n",
    "val_fpr, val_tpr, val_thresholds = roc_curve(val_pred_df['label'], val_pred_df['churnProba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "trn_trace = go.Scatter(\n",
    "    x=trn_fpr,\n",
    "    y=trn_tpr,\n",
    "    text=trn_thresholds,\n",
    "    name='Training',\n",
    "    mode='lines',\n",
    "#     fill='tozeroy'\n",
    ")\n",
    "\n",
    "val_trace = go.Scatter(\n",
    "    x=val_fpr,\n",
    "    y=val_tpr,\n",
    "    text=val_thresholds,\n",
    "    name='Validation',\n",
    "    mode='lines',\n",
    "#     fill='tozeroy'\n",
    ")\n",
    "\n",
    "ns_trace = go.Scatter(\n",
    "    x=[0,1],\n",
    "    y=[0,1],\n",
    "    name='No Skill',\n",
    "    mode='lines',\n",
    "#     fill='tozeroy'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='ROC Curve for Final Model',\n",
    "    xaxis_range=[0,1],\n",
    "    yaxis_range=[0,1],\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    xaxis_tickformat='%',\n",
    "    yaxis_tickformat='%',\n",
    "    yaxis_scaleanchor='x',\n",
    "    yaxis_scaleratio=1\n",
    ")\n",
    "\n",
    "figure = go.Figure(\n",
    "    data=[trn_trace, val_trace, ns_trace],\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "figure.write_html('figures/roc_curve.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the confusion matrix look like if we set the threshold to 16% (for a tpr of 80%? on the validation dataset)\n",
    "trn_pred_df.loc[:, 'predictedLabelNew'] = trn_pred_df['churnProba'].map(lambda x: 1 if x >= 0.16 else 0)\n",
    "val_pred_df.loc[:, 'predictedLabelNew'] = val_pred_df['churnProba'].map(lambda x: 1 if x >= 0.16 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate updated confusion matrices\n",
    "trn_cmat = confusion_matrix(\n",
    "    y_true=trn_pred_df['label'],\n",
    "    y_pred=trn_pred_df['predictedLabelNew'])\n",
    "\n",
    "val_cmat = confusion_matrix(\n",
    "    y_true=val_pred_df['label'],\n",
    "    y_pred=val_pred_df['predictedLabelNew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training confusion matrix\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    trn_cmat,\n",
    "    colorscale='haline',\n",
    "    x=['No Churn', 'Churn'],\n",
    "    y=['No Churn', 'Churn'])\n",
    "fig.update_xaxes(side='bottom', title='Predicted Label')\n",
    "fig.update_yaxes(title='Actual Label')\n",
    "fig.update_layout(title='Confusion Matrix - Training Dataset @16%')\n",
    "fig.write_html('figures/cmat_train_tuned.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation confusion matrix\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    val_cmat,\n",
    "    colorscale='haline',\n",
    "    x=['No Churn', 'Churn'],\n",
    "    y=['No Churn', 'Churn'])\n",
    "fig.update_xaxes(side='bottom', title='Predicted Label')\n",
    "fig.update_yaxes(title='Actual Label')\n",
    "fig.update_layout(title='Confusion Matrix - Validation Dataset @16%')\n",
    "fig.write_html('figures/cmat_val_tuned.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sense-check, how separable are the two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>probability</th>\n",
       "      <th>label</th>\n",
       "      <th>predictedLabel</th>\n",
       "      <th>churnProba</th>\n",
       "      <th>dataset</th>\n",
       "      <th>predictedLabelNew</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000280</td>\n",
       "      <td>[0.677025680300048, 0.32297431969995205]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322974</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>No Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002185</td>\n",
       "      <td>[0.927641734964618, 0.07235826503538201]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072358</td>\n",
       "      <td>Training</td>\n",
       "      <td>0</td>\n",
       "      <td>No Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1033297</td>\n",
       "      <td>[0.9448878101412581, 0.05511218985874189]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055112</td>\n",
       "      <td>Training</td>\n",
       "      <td>0</td>\n",
       "      <td>No Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1057724</td>\n",
       "      <td>[0.9013045896844434, 0.09869541031555662]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098695</td>\n",
       "      <td>Training</td>\n",
       "      <td>0</td>\n",
       "      <td>No Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1059049</td>\n",
       "      <td>[0.8884397826922436, 0.11156021730775645]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111560</td>\n",
       "      <td>Training</td>\n",
       "      <td>0</td>\n",
       "      <td>No Churn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId                                probability  label  predictedLabel  \\\n",
       "0  1000280   [0.677025680300048, 0.32297431969995205]      0             0.0   \n",
       "1  1002185   [0.927641734964618, 0.07235826503538201]      0             0.0   \n",
       "2  1033297  [0.9448878101412581, 0.05511218985874189]      0             0.0   \n",
       "3  1057724  [0.9013045896844434, 0.09869541031555662]      0             0.0   \n",
       "4  1059049  [0.8884397826922436, 0.11156021730775645]      0             0.0   \n",
       "\n",
       "   churnProba   dataset  predictedLabelNew     class  \n",
       "0    0.322974  Training                  1  No Churn  \n",
       "1    0.072358  Training                  0  No Churn  \n",
       "2    0.055112  Training                  0  No Churn  \n",
       "3    0.098695  Training                  0  No Churn  \n",
       "4    0.111560  Training                  0  No Churn  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine datasets & add a text representation of the class for readability\n",
    "trn_pred_df.loc[:, 'dataset'] = 'Training',\n",
    "val_pred_df.loc[:, 'dataset'] = 'Validation'\n",
    "plot_df = pd.concat([trn_pred_df, val_pred_df], ignore_index=True, axis=0)\n",
    "plot_df.loc[:, 'class'] = plot_df['label'].map(lambda x: 'Churn' if x else 'No Churn')\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distribution plot to visualize churnProba between classes\n",
    "fig = px.histogram(\n",
    "    plot_df,\n",
    "    x='churnProba',\n",
    "    color='class',\n",
    "    histnorm='percent',\n",
    "    marginal='box',\n",
    "    title='Final Model - Class Separability',\n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.write_html('figures/class_separability.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('development': conda)",
   "language": "python",
   "name": "python38364bitdevelopmentcondad09183c7816a46e2b43cdb3043fcfb22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
